\cvprsection{引言}

近年来，随着深度学习等技术的迅猛发展，人工智能系统广泛应用于人脸识别、语音识别、自动驾驶、内容推荐等多个关键领域\cite{Mehrabi2021Survey}。然而，这些系统的部署同时也暴露出大量关于偏见和伦理的问题。例如，自动评估系统可能因训练数据中的历史歧视而强化性别或种族偏见；人脸识别系统在不同人群中的识别准确率差异引发公众对算法歧视的担忧。因此，AI 公平性与伦理问题成为当前学术界、工业界与政策制定者高度关注的研究课题。

公平性通常被定义为模型在不同群体或个体间的无差别表现，涵盖群体公平（Group Fairness）、个体公平（Individual Fairness）以及程序公平（Procedural Fairness）等多个视角\cite{Binns2018Fairness}。本文将系统梳理 AI 偏见的类型及成因，探讨当前的缓解方法，重点分析典型应用中的伦理困境，并总结全球相关法律法规的最新进展，最后展望未来研究方向。