\cvprsection{AI 系统中的多模态偏见问题}

随着多模态 AI 技术的迅猛发展，图像、文本、语音等多种模态的协同处理在诸如图文生成、语音助手、跨模态检索等应用中已成为核心趋势。

然而，多模态系统由于融合了不同来源和形式的数据，其偏见问题也变得更加复杂和隐蔽。在图文生成系统中，研究表明，当系统处理女性图像时，生成的描述往往倾向于使用“漂亮”、“温柔”、“年轻”等带有刻板印象的词汇；而男性图像则更常被配以“强壮”、“专业”、“领导力”等词语。这种现象揭示了文本与图像模态中的偏见并非独立存在，而是在多模态融合过程中相互强化，导致刻板印象在最终输出中被协同放大。

传统的单模态偏见缓解技术往往只能针对某一模态进行干预，难以有效应对模态之间的交互偏差。因此，迫切需要构建专门面向多模态系统的公平性评估指标，并设计融合阶段的偏见检测与纠正机制，从源头上减少交叉模态偏见的传播，提升系统输出的整体公平性、可解释性和社会责任感。