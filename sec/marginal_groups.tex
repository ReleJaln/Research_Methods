\cvprsection{边缘群体与少数数据问题}

训练数据中少数群体样本的缺乏被广泛认为是导致人工智能系统偏见的根本性原因之一。在多个关键领域，如医疗诊断、语音识别和自然语言处理，数据的分布往往严重失衡。例如，大多数医学图像数据集中白人男性患者占据主导地位，导致模型在处理非白人、女性或其他少数群体时准确率显著下降。在语音识别中，残障人士、口音差异显著的使用者以及低资源语言的说话者往往被系统忽略或误识，造成数字鸿沟进一步扩大。

为缓解这一问题，部分研究尝试采用再采样技术或使用生成对抗网络（GAN）合成数据，以补充少数群体样本。然而，合成数据往往难以完美模拟真实分布，其在临床和社会场景中的应用仍面临可信度和伦理安全的双重挑战。因此，未来需要从数据收集源头着手，结合差分隐私、联邦学习等隐私保护技术，安全地采集和整合更多来自边缘群体的真实数据，从而提升模型在各类人群中的泛化能力和公平性，构建更具包容性和社会责任感的人工智能系统。